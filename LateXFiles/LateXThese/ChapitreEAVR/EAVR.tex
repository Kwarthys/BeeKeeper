\chapter{Etat de l'art: Simulations Multi-Agents et Environnements Immersifs}
\label{ChapitreEAVR}

	Dans ce chapitre nous présentons différentes approches utilisées afin d'interagir avec des systèmes multi-agents, ainsi que différentes approches pour en visualiser certaines propriétés. Nous étendons ensuite nos observations à l'interaction et la visualisation en ce qui concerne les environnements immersifs, où l'utilisateur est plongé au cœur de l'application.
	
\boitemagique{Sébastien Picault \cite{picault_simulation_2013}}{"\textit{Pour être un tant soit peu polyvalent et pouvoir en particulier être utilisé pour la production de jeux vidéo, de simulateurs de conduite, etc., un moteur de simulation doit être en mesure de gérer non seulement des simulations « classiques » n'impliquant que des agents logiciels, mais également des situations dans lesquelles certains agents ont une matérialité extérieure au système : c'est le cas par exemple quand on doit interagir avec des réseaux de capteurs, des robots ou encore pire, des humains.}"}	

	\section{Visualiser et Interagir avec une Simulation Multi-Agents}
		
	Les systèmes multi-agents, du fait de leur taille, leur complexité et leur fonctionnement centré sur l'individu et ses interactions, amènent régulièrement de fortes contraintes sur la visualisation de leurs différents mécanismes.		
		
		\subsection{Visualisation de Simulations Multi-Agents}
		
		Les simulations multi-agents proposent le plus souvent deux types de visualisations : une visualisation "macro", orientée population, et une visualisation "micro", orientée individu. Par exemple, la plateforme \textit{GAMA} \cite{taillandier_building_2019} permet au concepteur du modèle multi-agents de créer différents types de visualisations. La Figure \ref{GAMA} illustre cette propriété, tirée des travaux réalisés pour développer GAMA \cite{taillandier_building_2019}. Elle montre à droite quatre visualisations "micro" de quatre simulations de fourmis, et à gauche une visualisation "macro" sous la forme d'un graphique montrant les quantités de nourritures ramassées par chacune des simulations, donc ici par chacune des colonies de fourmis.
		Les visualisations orientées population permettent en général d'observer les phénomènes émergents et/ou l'auto-organisation, là où les représentations micro, représentant souvent les agents eux mêmes ainsi que leur environnement, permettent d'observer la cohérence des comportements individuels par rapport aux attentes du concepteur. Cependant, si les visualisation "macro" permettent d'observer le résultat de l'auto-organisation ou de phénomènes émergents, elles permettent difficilement d'observer les mécanismes de mise en place et de maintient de ces phénomènes.
		
		\begin{figure}
			\centering
			\includegraphics[width=\textwidth]{Pictures/ScreenShots/GAMA.JPG}
			\caption{Tiré des travaux de Taillandier et al. \cite{taillandier_building_2019} sur la plateforme GAMA. Plusieurs visualisations pour un même simulateur dans GAMA.}
			\label{GAMA}
		\end{figure}
		
		Nous pouvons aussi mettre en place un visualisation totalement séparée de la simulation, dans un soucis de performances et de modularités. Cette séparation offre de pouvoir exécuter le modèle sans les contraintes de la visualisation, lorsqu'elle n'est pas nécessaire. Ainsi Louloudi et al. \cite{louloudi_new_2012} proposent un composant logiciel "relai" entre la simulation multi-agents et la visualisation agissant comme un convertisseur universel.
		Or, le types même de données à transmettre ainsi que les granularités de temps et d'espaces peuvent varier fortement au sein même d'un modèle multi-agents, mais aussi d'un modèle multi-agents à un autre, ce qui, couplé à un besoin de transmettre en retour des informations depuis l'application de visualisation vers le simulateur, rendent cette notion de relai \textit{universel} bien difficile à mettre en place.
		
		Nous voici désormais au cœur de la problématique, nous nous posons la question, "quoi visualiser" ? Un système multi-agents est certes composé d'une multitude d'agents, mais ces agents, à l'aide d'interactions constantes et multiples, génèrent un comportement complexe de plus haut niveau. Cette complexité, nous la retrouvons plus généralement dans les systèmes complexes, qui présentent aussi ces problématiques de visualisation.
		
		\subsubsection{Visualisation de Systèmes Complexes}
		\label{sectionVisuComplexe}
		
		La visualisation de systèmes multi-agents nous ramène très rapidement aux problèmes de visualisation de systèmes complexes. Pour illustrer cette problématique, Joël de Rosnay parle de "Macroscope" \cite{de_rosnay_macroscope_1975}. Nous disposons de télescopes pour observer l'infiniment loin, de microscopes pour ce qui est infiniment petit, il propose donc la notion de macroscope pour ce qui est infiniment complexe. Cet outil de visualisation ne pourrait pas, contrairement aux autres outils cités, se contenter de zoomer sur une image déjà existante, mais devrait construire une image, ou plusieurs, afin de rendre compte des différents mécanismes complexes régissant l'ensemble du système, à plusieurs échelles de taille, et de temps.
		
		Ainsi Hutzler dans ses travaux de thèse \cite{hutzler_du_2000} décompose ce processus de macroscope en trois étapes, qu'il décrit :
		
		"\textit{Pour ce faire, trois opérations sont nécessaires : \textbf{mesurer} le fonctionnement du système par un ensemble de données numériques, \textbf{filtrer et organiser} ces données, et enfin en \textbf{construire} une représentation sensible à destination de l'utilisateur.}" - Hutzler \cite{hutzler_du_2000}.

	En effet, la quantité de données brutes ne nous permet pas de simplement toutes les afficher, espérant qu'un observateur arrive à tirer du sens d'un flux continu de chiffres. Ainsi filtrer et traiter est essentiel, afin d'éliminer le bruit et de faire ressortir les propriétés intéressantes, que l'on souhaite transmettre à l'utilisateur.

		
		 Ces visualisations ont alors un intérêt au moins double. Elles permettent au concepteur de s'assurer que le modèle se comporte comme attendu, sans qu'un problème de conception ou un "\textit{bug}" ne vienne troubler le système. Elles permettent aussi au concepteur de communiquer sur sa simulation, afin de partager ses résultats, de les confronter à des experts non-initiés à la simulation, ou encore à des apprenants dans un cadre pédagogique.

		"\textit{Le scientifique a alors la responsabilité de traduire sous forme graphique le résultat de son travail, ce qui fait de lui, sinon un artiste, du moins un dessinateur.}" - Hutzler \cite{hutzler_du_2000}.

	Ainsi, tout concepteur des système multi-agents complexes se voit en charge de concevoir avec lui le macroscope adapté, tout particulièrement s'il souhaite expliquer et illustrer les phénomènes complexes à l'œuvre. Les différentes granularités (de temps et de taille) présentées par différents systèmes, mais aussi la variété de données intéressantes à observer, très dépendante de l'usage même de ce macroscope, rendent sa systématisation impossible. Que l'outil s'adresse à un "concepteur", à un "opérateur", ou encore à un "spectateur", sa forme ne sera pas du tout la même. Par exemple, l'emphase sera placée au niveau du fonctionnement du système pour un concepteur, alors qu'elle sera placée sur ses dysfonctionnements pour un opérateur.
		
	
	Si certaines propriétés émergentes sont directement observables, comme par exemple les autoroutes de fourmis, visibles dès que l'on observe l'emplacement individuel de leurs sous-systèmes, bien d'autres sont par natures inobservables, comme par exemple le processus permettant aux fourmis de trouver le chemin le plus court pour former leur autoroute vers de la nourriture. Il faut alors construire des métaphores, des représentations, capables de traduire le comportement inobservable afin qu'un utilisateur puisse s'en construire une représentation mentale fidèle au modèle complexe observé.

		"\textit{La construction d'un modèle cognitif pourra ainsi s'effectuer dans certains cas par la confrontation « directe » du sujet au système complexe, grâce à la médiation de son appareil sensori-moteur (essentiellement la vision, l'audition, le toucher, la proprioception). Mais cette construction s'effectuera également, dans d'autres cas, par la confrontation avec des représentations visuelles, sonores, langagières du monde, elles-mêmes élaborées pour mettre en évidence les parties d'un système et leurs interactions.}" - Hutzler \cite{hutzler_du_2000}.
		
		Hutzler illustre ici l'importance de la multi-modalité dans la visualisation, en plus de la multiplications des visualisations. Il présente ensuite en quoi la vision est le médium le plus adapté pour transmettre de grandes quantités de données, et qu'il peut être renforcé par l'utilisation d'autres sens. Il souligne toutefois la forte subjectivité que représente l'action de percevoir. En effet, les illusions d'optiques illustrant ce point sont nombreuses : la culture, l'expérience et bien d'autres facteurs peuvent influencer la manière dont nous percevons une même image.
		
		Ensuite, plusieurs lignes de conduite que bous allons décrire sont énoncées :
		\begin{itemize}
			\item Diversité de formes de représentation : proposer d'observer différents composants hétérogènes comme tel, ou comme s'ils étaient homogènes, au choix de l'utilisateur.
			\item Diversité des niveaux de représentation : visualiser les composants de manières atomique ou composite, selon les besoins de l'utilisateur (il donne l'exemple d'une machine outil en fonctionnement qui peut être synthétisée par un cercle vert, mais lorsque celle-ci présente une erreur, la visualisation devra montrer l'ensemble de ses composants afin d'aider au diagnostic). On note une approche similaire, à base d'agrégation, dans les travaux de Lamarche-Perrin \cite{lamarche-perrin_analyse_2013}.
			\item Diversité de sources d'information : collecter les données nécessaires depuis plusieurs sources. Permettre aussi de les trier, traiter et organiser avant de les présenter à l'utilisateur.
			\item Modularité : ajouter / retirer dynamiquement des éléments, définir la composition de la représentation.
			\item Structuration : permettre d'observer la notion de structure, de hiérarchisation en niveaux, dynamiquement selon les besoins de l'utilisateur.
			\item Interaction : permettre d'observer les actions et perceptions des différents composants, et "permettre de manipuler une interaction à la manière d'un composant". (Il donne ici le statut de composant aux interactions elles mêmes.)
		\end{itemize}
		
		Après avoir étudié les enjeux et lignes de conduites pour la visualisation de systèmes complexes, et par extension de systèmes multi-agents, nous allons désormais aborder différents points concernant les interactions avec des simulations à base d'agents.
		
		\subsection{Interactions avec des Systèmes Multi-Agents}
		%Systèmes en général non immersif, on s'arrête à la RA, et [de ce que j'ai vu], sans utilisation d'interacteurs tangibles.
	%Comment mieux comprendre un système complexe : Environnement immersif et interacteurs tangibles. Ruche, cadre et connaissances apicoles.
	
	
		Nous trouvons dans la littérature 4 grands principes d'interactions avec une simulation multi-agents \cite{kolling_human_2016} :
		\begin{enumerate}
			\item Modification de paramètres de la simulation ou de l'algorithme des agents.
			\item Contrôle du comportement général des agents.
			\item Contrôle indirect via modification de l'environnement.
			\item Prise de contrôle d'un agent afin d'influencer les autres.
		\end{enumerate}
		
		
	\subsubsection{Modification de Paramètres}
	Les systèmes multi-agents reposent sur une grande quantité de paramètres, qu'il est donc possible de faire varier pour en observer l'influence. Cependant, certains de ces paramètres ont un impact imprévisible sur le comportement du système en général, du fait de l'émergence de nombreuses propriétés de celui-ci \cite{couzin_collective_2002}. Il est donc difficile de proposer le comportement inverse : laisser l'utilisateur choisir un paramètre concernant des propriétés émergentes, puis retrouver quels paramètres individuels adapter pour retrouver la propriété demandée. Kira et Potter \cite{kira_exerting_2009} ont proposé une approche utilisant de l'apprentissage automatique, du \textit{machine learning}, pour réaliser cette fonction.
	
	Ce type d'interaction compte aussi les contrôles de la simulation elle-même : la lancer, la mettre en pause, l'accélérer, l'arrêter etc. Ces contrôles sont le plus souvent directement présents au niveau des plateformes présentant des environnements de simulations.
		
	\subsubsection{Contrôle du Comportement}
	À l'inverse, la sélection de comportement permet un contrôle de très haut niveau. Ici, au lieu de changer un paramètre, l'utilisateur peut changer la manière d'opérer des agents qu'il sélectionne, changer leur algorithme, pour leur demander par exemple de suivre, d'éviter, ou encore de surveiller d'autres robots ou lieux \cite{coppin_controlling_2012}. Ceci implique que la simulation propose un ensemble de ces algorithmes que les agents soient capables d'exécuter et que l'utilisateur en connaisse les implications, fonctions. L'utilisateur doit aussi connaitre la répartition spatiale des agents.
	
		
		
	\subsubsection{Modifications de l'Environnement}
		Il est aussi possible d'interagir avec une grande quantité d'agents en influant sur leur environnement. Par exemple, Walter et al. \cite{walter_uav_2006} utilisent un champ de phéromones virtuelles pour diriger jusqu'à 50 000 drones sous-marins virtuels. Les phéromones permettent de facilement leur faire éviter une zone, ou à l'inverse les faire converger vers une zone définie. Nous trouvons aussi l'utilisation d'objets répulsifs placés dans l'environnement de robots agissant en essaim, afin d'indirectement contrôler la forme de ce dernier \cite{jung_multi-robot_2013}.	
	
		De la même manière, certains jeux vidéo de gestion proposent à leur manière un mode d'interaction avec un système multi-agents. Tel "\textit{Populous}", "\textit{Dwarf Fortress}" ou "\textit{Banished}", les "\textit{god games}" et certains jeux de gestions proposent des simulations complexes dont les agents ne sont pas directement contrôlables. L'utilisateur (ici le joueur) interagit avec la simulation à travers des ordres de haut niveau, que les agents vont interpréter puis réaliser en suivant leurs propres règles (d'où la dénomination "god game", le joueur agit comme le "dieu" de la simulation). Par exemple, le joueur peut demander la construction d'un certain bâtiment à un endroit précis. Les agents disponibles, s'il y en a, se mettront à la tâche, s'interrompant s'ils en ont besoin sans que le joueur ne puisse intervenir. 
		
		Nous plaçons ainsi ce type d'interaction en une manipulation de l'environnement des agents, mais il aurait aussi sa place, dans certains cas, dans la catégorie de contrôle du comportement.
	
	\subsubsection{Prise de Contrôle d'un Agent}
		Ce type d'interaction se retrouve dans le modèle "Voyelles" proposé par Y. Demazeau \cite{demazeau_interactions_1995}. Celui-ci analyse les modèles multi-agents sous 4 points de vues : "\textbf{A}gents", "\textbf{E}nvironnement", "\textbf{I}nteractions" et "\textbf{O}rganisations" (AEIO). Là où ce modèle nous intéresse dans ce chapitre, c'est lorsque J. Tisseau propose d'y ajouter le "U" d'"\textbf{U}tilisateur" \cite{tisseau_realite_2001}, pour former "AEIOU". Dans cette définition, l'utilisateur intervient à souhait dans la simulation, en prenant le contrôle d'un agent, utilisant ses capacités motrices et surchargeant son module de décision. Les autres agents de la simulation réagissent alors à l'utilisateur comme s'il était toujours un agent tout à fait normal. 
		L'utilisateur possède ainsi, à volonté, un "avatar" dans la simulation, interagissant tel un émissaire virtuel avec l'environnement, avec l'ensemble des autres agents (qui peuvent être des avatars d'autres utilisateurs) et autres systèmes modélisés. Il interagit alors avec les agents de la simulation de manière "horizontale". Par exemple, dans le \textit{serious game} "FORMAT-STORE" \cite{mathieu_serious_2011}, le joueur prend le contrôle de l'agent "vendeur" qu'il contrôle avec clavier et souris, et interagit avec les autres agents "clients" de l'environnement, les étales et le magasin.
		
		À l'inverse, l'agent contrôlé peut avoir une grande influence sur le comportement de la simulation, dans le rôle de "\textit{leader}" des autres agents. Ainsi, l'utilisateur est capable de contrôler le comportement d'un grand nombre d'agents, en n'en contrôlant qu'un seul, ou quelques uns, comme les agents dits "\textit{stakeholders}" des travaux de Brown et al. \cite{brown_human-swarm_2014}, influant sur les autres agents au point de permettre le contrôle de la forme de l'ensemble du groupe d'agents.
	
	
	\section{Visualisation et Interactions en Environnements Immersifs}	
	
	Nous élargissons désormais nos recherches aux environnements immersifs en général, sans applications directes aux systèmes multi-agents. Ces travaux serviront de base à notre réflexion, couplés à ce que nous avons déjà vu concernant les interactions et visualisations avec des modèles multi-agents.
	
	\subsection{Visualisation en Environnements Immersifs}
	
	Les trois dimensions offertes par les environnements immersifs font de la position dans l'espace la manière principale d'afficher des données. Placées par rapport à un autre objet, comme des unités représentées sur une carte \cite{durbin_battlefield_1998} ou des pathologies sur un corps \cite{coffey_interactive_2012}, les données permettent une lecture rapide et efficace. Ces données sont alors représentées elles-mêmes par un modèle 3D, qui peut lui aussi ajouter un niveau d'information sur leur nature. Certains auteurs utilisent même du son pour représenter l'intensité d'un paramètre, par exemple la métaphore du compteur Geiger \cite{frohlich_exploring_1999}.
	
	
		
		Certains travaux sur la visualisation des colonies d'abeilles visent principalement à aider les apiculteurs à prendre des décisions, en leur fournissant des informations sur les populations d'abeilles \cite{engelke_visual_2016, engelke_melissar_2016, nguyen_augmented_2017}. Par exemple, Engelke et al. \cite{engelke_visual_2016} utilisent la réalité augmentée pour afficher des données provenant de plusieurs capteurs dans une série de ruches réelles et permettre à l'utilisateur de parcourir toutes les données de manière intuitive et immersive. Ces données sont collectées au niveau de la ruche (macro), comme la température et le poids, puis sont affichées superposées en réalité augmentée aux ruches correspondantes, selon des graphiques et labels adaptés. Ils sont ainsi capables de savoir dans quelle ruche se trouvent certaines abeilles et d'étudier la "dérive des abeilles" : lorsque les abeilles d'une colonie partent butiner et rejoignent une autre colonie au retour.
	
	\subsubsection{Visualiser une Grande Quantité de Données}
	
	 Les visualisations de grandes quantités de données ont majoritairement pour but de permettre à l'utilisateur de découvrir des relations entre différents éléments, d'observer des schémas et/ou de détecter des données inhabituelles : les nuages de points sont souvent utilisés à ces fins \cite{nagel_methods_2001}.
	En plus des 3 axes que nous offrent les trois dimensions de l'environnement immersif pour placer nos points, nous pouvons aussi jouer sur leur forme, leur taille, leur couleur et transparence, permettant de rendre compte d'un grand nombre de variables. De cette manière, Donalek et al. \cite{donalek_immersive_2014} parviennent à afficher 8 dimensions de leurs données. Nagel et al. \cite{nagel_methods_2001} proposent aussi d'animer certaines de ces propriétés, afin d'apporter encore plus d'information. Par exemple, un point représenté par un triangle peut représenter un attribut d'une donnée, et le mouvement donné à cette représentation (par exemple faire tourner ce triangle sur lui même, ou le faire vibrer ), peut représenter une autre caractéristique de cette même donnée.
	
	\subsection{Interactions en Environnements Immersifs}
	
	Fondateurs dans le domaine, Bowman et al. \cite{bowman_introduction_2001} divisent les interactions utilisateurs en environnements virtuels en trois grandes catégories que nous allons décrire une par une :
	\begin{itemize}
		\item Navigation : comment l'utilisateur va se déplacer dans l'environnement.
		\item Sélection et Manipulation : comment l'utilisateur va dire à l'environnement quel(s) objet(s) il souhaite manipuler, et comment va-t-il les manipuler.
		\item Contrôle du système : comment l'utilisateur va altérer le déroulement même du système, de la simulation.
	\end{itemize}.
	
	\subsubsection{Naviguer dans un Environnement Virtuel}
		La navigation permet à l'utilisateur de changer son point de vue sur l'environnement, elle doit aussi renforcer son immersion et l'aider à se repérer dans l'espace virtuel. Mal gérée, la navigation risque de provoquer la cinétose selon la sensibilité de l'utilisateur, semblable au mal des transports. La navigation est elle-même divisée en trois modes : exploration, recherche et manœuvre, demandant différents degrés de contrôle. Dans ces travaux, Bowman et al. décrivent cinq métaphores classiquement utilisées pour les déplacements, que nous allons aborder rapidement :
		\begin{itemize}
		\item \textbf{Déplacement physique} : les mouvements du corps de l'utilisateur sont utilisés pour déplacer la caméra de l'environnement virtuel. Ceci est possible lorsque l'espace physique dans lequel est présent l'utilisateur est assez grand, et présente alors les meilleurs conditions pour l'utilisateur \cite{cherep_spatial_2020}. Les auteurs mentionnent aussi l'utilisation possible d'un tapis roulant ou d'un vélo immobilisé, permettant à l'utilisateur de se déplacer physiquement tout en faisant du sur-place, limitant l'espace physique nécessaire.
		\item \textbf{Déplacement "manuel"} : l'utilisateur vient saisir "l'air" l'environnant et le "tire" vers lui, se déplaçant alors vers le point saisi, rappelant la métaphore d'une corde. Cette méthode fatigante est dite facile à prendre en main.
		\item \textbf{Conduite} : l'utilisateur indique une direction, souvent la direction de son regard ou la direction pointée par une de ses manettes, dictant la direction du mouvement. Les auteurs présentent cette méthode comme étant efficace et générique. 
		\item \textbf{Sélection du point d'arrivée} : l'utilisateur indique le point auquel il souhaite se rendre et l'application se charge de l'y déplacer, en translation ou téléportation. Bowman et al. plébiscitaient à leur époque la translation plutôt que la téléportation, mais le déplacement de l'environnement sans déplacement du corps de l'utilisateur provoque la cinétose de celui-ci \cite{cherep_spatial_2020}.
		\item \textbf{Planification d'itinéraire} : un peu à la manière du déplacement précédent, l'utilisateur définit différents points de passages pour sa trajectoire. Ici encore, les risques de cinétoses sont élevés.
		\end{itemize}
		
	\subsubsection{Sélection et Manipulation dans un Environnement Virtuel}
	Ce type d'interaction permet à l'utilisateur de sélectionner un objet à manipuler, et d'en altérer la position et rotation dans l'environnement. Deux grands types d'interactions se retrouvent dans cette catégorie. Le premier consiste à capter la position de la main de l'utilisateur et de la représenter dans l'environnement virtuel, lui permettant de saisir les objets que sa main virtuelle "touche". La méthode "Go-Go" permet d'agrandir la portée de l'utilisateur au delà de la taille de son bras : la longueur de son bras virtuel devient une fonction non-linéaire de celle de son bras réel \cite{poupyrev_go-go_1996}, lui permettant d'atteindre des objets éloignés tout en conservant une interaction naturelle. L'autre méthode consiste en un rayon laser tiré depuis l'utilisateur (souvent sa main, donnée par l'orientation et la position de la manette) qui vient sélectionner l'objet ainsi visé. 
	
	Ces méthodes permettent aussi de représenter le "clic" traditionnel des interfaces classiques sur des boutons d'interface 2D, utilisables alors sur des interfaces 2D "flottantes" dans l'environnement virtuel.
	
	\subsubsection{Contrôle du Système dans un Environnement Virtuel}
	Ces contrôles permettent à l'utilisateur de modifier le fonctionnement de la simulation, ou de ses interactions, en sélectionnant le plus souvent des comportements prédéfinis. Ces interactions sont mises en place de manière similaire aux précédentes lorsque sont utilisés des menus tirés des interfaces 2D. Mais des commandes vocales, des commandes gestuelles ou l'utilisation d'outils réel dont la position a un sens permettent aussi de piloter ce genre d'interactions.
	
	
	\subsubsection{Interacteurs Tangibles}
	
		\begin{figure}
			\centering
			\includegraphics[width=.8\textwidth]{Pictures/Figures/TUIISHII.JPG}
			\caption{Tiré des travaux de Ishii et al. \cite{ishii_tangible_1997}. Équivalences entre des interacteurs "WIMP" et leurs homologues tangibles.}
			\label{TUIEx}
		\end{figure}	
	
			D'abord théorisé sous le nom d'"interfaces saisissables" \cite{fitzmaurice_bricks_1995}, le concept est ensuite étendu et devient "interfaces tangibles". Les interfaces tangibles (TUI pour \textit{Tangible User Interface}) incarnent une volonté de sortir des interfaces classiques dites "WIMP", "\textit{Windows, Icon, Menu, Pointer}", pour aller vers des interacteurs physiques ayant une représentation et une sémantique numérique, que l'on manipule naturellement \cite{ishii_tangible_1997}, la Figure \ref{TUIEx} en illustre quelques exemples. Dans leurs travaux, Ihsii et al. \cite{ishii_tangible_1997} proposent notamment l'utilisation de tables interactives "metaDESK", capables de détecter et d'interpréter la sémantique d'objets posés sur sa surface. De la même manière, un tableau blanc pourrait reconnaitre des objets à sa surface. Ils proposent ensuite une "ambientROOM", littéralement "salle d'ambiance", où ils combinent l'utilisation d'une table interactive "cognitivement intensive" à des sensations périphériques pour convier des informations complémentaires. À ces fins, ils utilisent des sons, des déplacements d'air ou des lumières ambiantes.
			
			\begin{figure}
			\centering
			\includegraphics[width=.8\textwidth]{Pictures/Figures/KnobSlider.JPG}
			\caption{Tiré des travaux de Kim et al. \cite{kim_knobslider_2019}. Le "KnobSlider", un interacteur tangible capable de changer de forme afin de servir soit de bouton rotatif (C), soit de slider (A).}
			\label{KnobSlider}
		\end{figure}
			
			Leurs applications sont diverses, permettant par exemple une assistance pour la construction de requêtes complexes sur une base de données \cite{pereda_tui_2019}, ou une proposition de surfaces interactives permettant de jouer à un jeu de société "augmenté" \cite{villar_project_2018}. Plusieurs travaux s'intéressent à la forme de l'interacteur tangible, centrale dans la notion d'affordance, comme par exemple la proposition du "KnobSlider", un interacteur changeant de forme afin de proposer deux interactions, une interaction de bouton à tourner et une interaction de "slider" (bouton glissière), visibles sur la Figure \ref{KnobSlider} \cite{kim_knobslider_2019}. Dans la même recherche d'une forme modulable, des travaux proposent un interacteur à base de \textit{LEGO}, et donc complètement personalisable, afin de servir différents besoins, selon les applications ou les jeux \cite{arora_virtualbricks_2019}.
				
			Les TUI ont par la suite prouvé leurs capacités à faciliter l'immersion et l'apprentissage de ses utilisateurs \cite{zuckerman_tui_2013, fleck_marker-based_2015, cheng_affordances_2013}, et sont donc nombreux dans les applications pédagogiques. Par exemple, \textit{DEAPE Learn} propose une combinaison d'objets tangibles et de réalité augmentée afin d'illustrer et d'enseigner différents principes d'électromagnétisme, qui sont connus pour être abstrait et difficiles à comprendre pour les étudiants \cite{da_costa_realite_2019}. Une loupe augmentée est proposée dans des travaux visant à rapprocher les visiteurs de musées des différentes œuvres, en proposant des informations complémentaires aux objets que les utilisateurs regardent à travers elle  \cite{damala_loupe_2016}. Un peu différemment, Veytizou et al. ont proposé d'utiliser une balance et des sphères de poids équivalents pour permettre à des enfants de répondre à une question de type "Likert", de 1 à 5 (ou 7). Les enfants sont connus pour donner des réponses très extrêmes à ces échelles, et l'utilisation de leur balance à réduit cette propension aux extrêmes tout en conservant des notes cohérentes \cite{veytizou_could_2018}.
	
	La notion de "confrontation directe" de l'utilisateur au système complexe étudié lue plus tôt dans une citation de Hutzler \cite{hutzler_du_2000} peut ainsi directement se rapporter aux interactions tangibles en environnement immersif. Ainsi, l'utilisateur utilise ses propres facultés sensori-motrices, immergé dans l'environnement virtuel avec le système qu'il observe et manipule.
	
				
	\section*{Conclusion}
	
		Nous avons vu dans ce chapitre que représenter un système multi-agents et interagir avec n'est pas trivial. Souvent visualisés via deux échelles différentes, une échelle micro concernant chaque individu (leur énergie, leur faim, leur action en cours etc.), et une échelle macro concernant le système lui même (la population, la démographie, les objectifs etc.), les simulations à base d'agents nécessitent parfois des niveaux intermédiaires. Il est aussi possible d'utiliser des abstractions, et/ou des métaphores, afin d'augmenter la qualité de l'information transmise à l'observateur. Le macroscope est un outil lui même complexe, et dépend de ce qu'en attends l'utilisateur. Il sera en effet différent pour un "concepteur", un "spectateur" ou encore un "opérateur".
		
		Ensuite différents niveaux d'interactions sont possibles avec les agents, du très haut niveau en contrôlant leur paramètres ou la vitesse de la simulation jusqu'à un très bas niveau où, par exemple, l'utilisateur prend le contrôle d'un agent ou en modifie quelques propriétés.
		
		L'environnement immersif nous offre une troisième dimension, étoffant les possibilités de visualisation et de manipulation. L'utilisateur doit alors pouvoir naviguer dans l'environnement, sélectionner et manipuler différentes entités et pouvoir contrôler l'application en elle-même. Les interfaces tangibles proposent des interactions naturelles, afin de faciliter l'apprentissage et/ou la prise en main de situations virtuelles complexes.
		
		Nous présentons dans le chapitre suivant nos différentes propositions concernant les moyens d'interactions et de visualisations avec notre système multi-agents d'une colonie d'abeilles. Nous proposons dans une première version l'utilisation d'un interacteur tangible couplé à l'utilisation d'une manette du casque de réalité virtuelle, afin de confronter directement l'utilisateur à la colonie, de manière immersive.	
		L'utilisateur peut alors manipuler la colonie virtuelle via l'interacteur tangible, et en observer la représentation "\textit{concrète}" : la ruche et ses cadres, sur lesquels apparaissent nos abeilles virtuelles.
		Il pourra aussi observer la colonie via un nuage de points en trois dimensions, représentation "\textit{abstraite}" de l'état interne de la colonie et ainsi des mécanismes de l'auto-organisation dont fait preuve la colonie.