\chapter{Etat de l'art: Simulations Multi-Agents et Environnements Immersifs}
\label{ChapitreEAVR}

	Dans ce chapitre nous présentons différentes approches utilisées afin d'interagir avec des systèmes multi-agents, ainsi que différentes approches pour les en visualiser différentes propriétés. Nous étendons ensuite nos observations à l'interaction et la visualisation en ce qui concerne les environnement immersifs, où l'utilisateur est plongé au cœur de l'application, souvent grâce à un casque de réalité virtuelle.
	
\boitemagique{Sébastien Picault \cite{picault_simulation_2013}}{"\textit{Pour être un tant soit peu polyvalent et pouvoir en particulier être utilisé pour la production de jeux vidéo, de simulateurs de conduite, etc., un moteur de simulation doit être en mesure de gérer non seulement des simulations « classiques » n'impliquant que des agents logiciels, mais également des situations dans lesquelles certains agents ont une matérialité extérieure au système : c'est le cas par exemple quand on doit interagir avec des réseaux de capteurs, des robots ou encore pire, des humains.}"}	

	\section{Visualiser et Interagir avec une Simulation Multi-Agents}
		
		
		\subsection{Visualisation de Simulations Multi-Agents}
		
		\subsubsection{Visualisation Micro-Macro}
		Les simulations multi-agents proposent le plus souvent deux types de visualisation : une visualisation "macro", orientée population, et une visualisation "micro", orientée individu. Par exemple, la plateforme \textit{GAMA} \cite{taillandier_building_2019} propose différents niveaux de visualisations, permettant au concepteur du modèle multi-agents de créer ces différentes visualisations.
		
		Les visualisations orientées populations permettent en général d'observer les phénomènes émergents et/ou l'auto-organisation, là où les représentations micro, représentant souvent les agents eux mêmes ainsi que leur environnement, permettent d'observer la cohérence des comportements individuels par rapport aux attentes du concepteur.
		
		Ensuite nous voici au problème, la question, "quoi visualiser" ? Un système multi-agents est certes composés d'une multitude d'agents, mais ces agents, à l'aide d'interactions constantes multiples, génèrent un comportement complexe de plus haut niveau. Cette complexité, nous la retrouvons plus en général dans les systèmes complexes.
		
		\subsubsection{Visualisation de Systèmes Complexes}
		
		La visualisation de systèmes multi-agents nous ramène très rapidement aux problèmes de visualisation de systèmes complexes, dont ils font souvent partie. Pour illustrer cette problématique, Joël de Rosnay parle de "Macroscope" \cite{de_rosnay_macroscope_1975}. Nous disposons de télescopes pour observer l'infiniment loin, de microscope pour ce qui est infiniment petit, il propose donc la notion de macroscope pour ce qui est infiniment complexe. Cet outil de visualisation ne pourrait pas, contrairement aux autres outils cités, se contenter de zoomer sur une image déjà existante, mais devrait construire une image, ou plusieurs, afin de rendre compte des différents mécanismes complexes régissant l'ensemble du systèmes, à plusieurs échelles de taille, et de temps.
		
		Ainsi Hutzler dans ces travaux de thèse \cite{hutzler_du_2000} décompose se processus de macroscope en trois étape, qu'il décrit :
		
		"\textit{Pour ce faire, trois opérations sont nécessaires : \textbf{mesurer} le fonctionnement du système par un ensemble de données numériques, \textbf{filtrer et organiser} ces données, et enfin en \textbf{construire} une représentation sensible à destination de l'utilisateur.}" - Hutzler \cite{hutzler_du_2000}.

	En effet la quantité de données brutes ne permet pas de simplement toutes les afficher, espérant qu'un observateur arrive à tirer du sens d'un flux continu de chiffres. Ainsi filtrer et traiter est essentiel, afin d'éliminer le bruit et de faire ressortir les propriétés intéressantes, que l'on souhaite transmettre à l'utilisateur.

		
		 Ces visualisations ont alors un intérêt au moins double. Elles permettent au concepteur de s'assurer que le modèle se comporte comme attendu, sans qu'un problème de conception, un "\textit{bug}", ne vienne troubler le système. Elles permettent aussi au concepteur de communiquer sur sa simulation, afin de partager ses résultats, de les confronter à des experts non-initiés à la simulation, ou encore dans un cadre pédagogique.

		"\textit{Le scientifique a alors la responsabilité de traduire sous forme
graphique le résultat de son travail, ce qui fait de lui, sinon un artiste, du moins un dessinateur.}" - Hutzler \cite{hutzler_du_2000}.

	\paragraph{}
	Ainsi, tout concepteur de système multi-agents complexes se voit en charge de concevoir avec lui un macroscope. Les différentes granularités présentées par différents systèmes, mais aussi la variété de données intéressantes à observer, très dépendante de l'usage même de ce macroscope, rendent sa systématisation impossible. Que l'outil s'adresse à un "concepteur", à un "opérateur", ou encore à un "spectateur", nous ressentons instinctivement que sa forme ne sera pas du tout la même. 
	Si certaines propriétés émergentes sont directement observables, comme par exemple les autoroutes de fourmis, visibles dès que l'on observe l'emplacement individuel de ses sous-systèmes, bien d'autres sont par natures inobservables, comme par exemple le processus permettant aux fourmis de trouver le chemin le plus court pour former leur autoroute vers de la nourriture. Il faut alors construire des métaphores, des représentations, capables de traduire le comportement inobservable afin qu'un utilisateur puisse s'en construire une représentation mentale fidèle au modèle complexe observé.

		"\textit{La construction d'un modèle cognitif pourra ainsi s'effectuer dans certains cas par la confrontation « directe » du sujet au système complexe, grâce à la médiation de son appareil sensori-moteur (essentiellement la vision, l'audition, le toucher, la proprioception). Mais cette construction s'effectuera également, dans d'autre cas, par la confrontation avec des représentations visuelles, sonores, langagières du monde, elles-mêmes élaborées pour mettre en évidence les parties d'un système et leurs interactions.}" - Hutzler \cite{hutzler_du_2000}.
		
		\subsection{Interactions avec des Systèmes Multi-Agents}
		%Systèmes en général non immersif, on s'arrête à la RA, et [de ce que j'ai vu], sans utilisation d'interacteurs tangibles.
	%Comment mieux comprendre un système complexe : Environnement immersif et interacteurs tangibles. Ruche, cadre et connaissances apicoles.
	
	
		Nous trouvons dans la littérature 4 grands principes d'interactions avec une simulation multi-agents \cite{kolling_human_2016} :
		\begin{enumerate}
			\item Modification de paramètres de la simulation ou de l'algorithme des agents
			\item Contrôle du comportement général des agents
			\item Contrôle indirect via modification de l'environnement
			\item Prise de contrôle d'un agent afin d'influencer les autres
		\end{enumerate}
		
		
	\subsubsection{Modification de Paramètres}
	Les systèmes multi-agents reposent sur une grande quantité de paramètres, qu'il est donc possible de faire varier pour en observer les conséquences. Cependant, certains de ces paramètres ont un impact imprévisible sur le comportement du système en général, du fait de l'émergence de nombreuses propriétés de celui-ci \cite{couzin_collective_2002}. Il est donc difficile de proposer le comportement inverse : laisser l'utilisateur choisir un paramètre concernant des propriétés émergentes, puis retrouver quels paramètres individuels adapter pour retrouver la propriété demandée. Kira et Potter \cite{kira_exerting_2009} ont proposé une approche \textit{machine learning} pour réaliser cette fonction.
	
	Ce type d'interaction se réalise à un niveau très proche de l'implémentation de l'agent, nous parlerons donc ici d'interaction bas niveau.
	
	\paragraph{}
	Ce type d'interaction compte aussi les contrôles de la simulation elle même, la lancer, la mettre en pause, l'accélérer, l'arrêter etc. Ces contrôles sont le plus souvent directement présent au niveau des plateformes présentant des environnements de simulations.
		
	\subsubsection{Contrôle du Comportement}
	À l'inverse des interactions bas niveau, la sélection de comportement permet un contrôle très haut niveau. Ici, au lieu de changer un paramètre, l'utilisateur peut changer la manière d'opérer des agents qu'il sélectionne, changer leur algorithme, pour leur demander par exemple de suivre, d'éviter, ou encore de surveiller d'autres robots ou lieux \cite{coppin_controlling_2012}. Ceci implique que la simulation propose un ensemble de ces algorithmes que les agents soient capables de tous d'exécuter et que l'utilisateur connaissent les implications et fonctions de ces différents comportements sur les agents, ainsi que la répartition spatiales de ces derniers.
	
		
		
	\subsubsection{Modifications de l'Environnement}
		Il est aussi possible d'interagir avec une grande quantité d'agents en influant sur leur environnement. Par exemple, Walter et al. \cite{walter_uav_2006} utilisent un champ de phéromones virtuelles pour diriger jusqu'à 50 000 drones sous-marins. Les phéromones permettent de facilement leur faire éviter une zone, ou à l'inverse les faire converger vers une zone définie. Nous trouvons aussi l'utilisation d'objets répulsifs placés dans l'environnement de robots agissant en essaim, afin d'indirectement contrôler la forme de ce dernier \cite{jung_multi-robot_2013}.	
	
		De la même manière, certain jeux vidéo de gestion proposent à leur manière un mode d'interaction avec un système multi-agents. Tel "\textit{Populous}", "\textit{Dwarf Fortress}" ou "\textit{Banished}", les "\textit{god games}" et certains jeux de gestions proposent des simulations complexes dont les agents ne sont pas directement contrôlables. L'utilisateur (ici le joueur) interagit avec la simulation à travers des ordres de hauts niveaux, que les agents vont interpréter puis réaliser en suivant leurs propres règles (d'où la dénomination "god game", le joueur agit comme le "dieu" de la simulation). Par exemple, le joueur peut demander la construction d'un certain bâtiment à un endroit précis. Les agents disponibles, s'il y en a, se mettront à la tâche, s'interrompant s'ils en ont besoin sans que le joueur ne puisse intervenir. 
		
		Nous plaçons ainsi ce type d'interaction en une manipulation de l'environnement des agents, mais il aurait aussi sa place, dans certains cas, dans la catégorie de contrôle du comportement.
	
	\subsubsection{Prise de Contrôle d'un Agent}
		Ce type d'interaction se retrouve dans le modèle "Voyelles" proposé par Y. Demazeau \cite{demazeau_interactions_1995}. Celui-ci analyse les modèles multi-agents sous 4 points de vues : "\textbf{A}gents", "\textbf{E}nvironnement", "\textbf{I}nteractions" et "\textbf{O}rganisations" (AEIO). Là où ce modèle nous intéresse dans ce chapitre, c'est lorsque J.Tisseau propose d'y ajouter le "U" d'"\textbf{U}tilisateur" \cite{tisseau_realite_2001}, pour former "AEIOU". Dans cette définition, l'utilisateur intervient à souhait dans la simulation, en prenant le contrôle d'un agent, utilisant ses capacités motrices et surchargeant son module de décision. Les autres agents de la simulation réagissent alors à l'utilisateur comme s'il était toujours un agent tout à fait normal. 
		L'utilisateur possède ainsi, à volonté, un "avatar" dans la simulation, interagissant tel un émissaire virtuel avec l'environnement, avec l'ensemble des autres agents (qui peuvent être des avatars d'autres utilisateurs) et autres systèmes modélisés. Il interagit alors avec les agents de la simulation de manière "horizontale". Par exemple, dans le \textit{serious game} "FORMAT-STORE" \cite{mathieu_serious_2011}, le joueur prend le contrôle de l'agent "vendeur" qu'il contrôle avec clavier et souris, et interagit avec les autres agents "clients" de l'environnement, les étales et le magasin.
		
		À l'inverse, l'agent contrôlé peut avoir une grande influence sur le comportement de la simulation, dans le rôle de "\textit{leader}" des autres agents. Ainsi, l'utilisateur est capable de contrôler le comportement d'un grand nombre d'agents, en n'en contrôlant qu'un seul, ou quelques uns, comme les agents dits "\textit{stakeholders}" des travaux de Brown et al. \cite{brown_human-swarm_2014}.
	
	
	\section{Visualisation et Interactions en Environnements Immersifs}	
	
	Nous élargissons désormais nos recherches aux environnements immersifs en général, sans applications directes aux systèmes multi-agents. Ces travaux serviront de base à notre réflexion, couplée à ce que nous avons déjà vu concernant les interactions et visualisations avec des modèles multi-agents.
		
		Louloudi et. al. \cite{louloudi_new_2012} ont proposé dans leurs travaux de séparer la partie simulation multi-agents de la partie visualisation de leur programme. Cette séparation offre de pouvoir faire tourner le modèle sans les contraintes de la visualisation (souvent le respect du temps réel) lorsque la visualisation n'est pas nécessaire. Ils proposent un composant logiciel "relai" entre la simulation et la visualisation agissant comme un convertisseur universel. Or, les granularité de temps et d'espaces peuvent varier fortement d'un modèle multi-agents à un autre, ainsi que le type même de données à transmettre, ce qui, couplé à un besoin de transmettre en retour des informations depuis l'application de visualisation vers le simulateur rendent cette notion de relai \textit{universel} bien difficile à mettre en place.
	
	\subsection{Visualisation en Environnements Immersifs}
	
	Les trois dimensions offertes par les environnements immersifs font de la position dans l'espace la manière principale d'afficher des données. Placées par rapport à un autre objet, comme des unités représentées sur une carte \cite{durbin_battlefield_1998} ou des pathologie sur un corps \cite{coffey_interactive_2012}, la position des données permet une lecture rapide et efficace. Ces données sont alors représentées elles même par un modèle 3D, qui lui peut lui aussi ajouter un niveau d'information sur leur nature. Certains auteurs utilisent même du son pour représenter l'intensité d'un paramètre, comme la métaphore du compteur Geiger \cite{frohlich_exploring_1999}.
	
	
		
		Les travaux connexes sur la visualisation des colonies d'abeilles visent principalement à aider les apiculteurs à prendre des décisions, en leur fournissant des informations sur les populations d'abeilles \cite{engelke_visual_2016, engelke_melissar_2016, nguyen_augmented_2017}. Par exemple, Engelke et. al. \cite{engelke_visual_2016} utilisent la réalité augmentée pour afficher des données provenant de plusieurs capteurs dans une série de ruches réelles et permettre à l'utilisateur de parcourir toutes les données de manière intuitive et immersive. Ces données sont collectées au niveau de la ruche (macro), comme la température et le poids, puis sont affichées superposées aux ruches correspondantes en réalité augmentée, selon des graphiques et labels adaptés. Ils sont ainsi capables de savoir dans quelle ruche se trouvent certaines abeilles et d'étudier la "dérive des abeilles" : lorsque les abeilles d'une colonie partent et rejoignent une autre colonie.
	
	\subsubsection{Visualiser une Grande Quantité de Données}
	
	 Les visualisations de grandes quantités de données ont majoritairement pour but de permettre à l'utilisateur d'observer des relations entre différents éléments, d'observer des schémas et/ou de détecter des données inhabituelles \cite{nagel_methods_2001}.
	Les nuages de points sont souvent utilisés à ces fins. En plus des 3 axes que nous offrent les trois dimensions de l'environnement immersif pour placer nos points, nous pouvons aussi jouer sur leur forme, leur taille, leur couleur et transparence, permettent de rendre compte d'un grand nombre de variables. De cette manière, Donalek et al. \cite{donalek_immersive_2014} parviennent à afficher 8 dimensions de leurs données. Nagel et al. \cite{nagel_methods_2001} proposent aussi d'animer certaines de ces propriétés, afin d'apporter encore plus d'information. Par exemple, un point représenté par un triangle peut représenter un type de donnée, et faire tourner ce triangle sur lui même, ou le faire vibrer, peut indiquer un autre paramètre.
	
	
	
	 Un nouvel axe peut permettre de réaliser des animations, permettant d'observer la répartition et les relations entre points changer, en fonction du temps par exemple.
	
	Il est toujours possible de traiter les données avant visualisation : lisser du bruit, agréger des données qui sont peu pertinentes seules, réaliser des opérations pour rendre des écarts plus visibles et bien d'autres.
	
	\subsection{Interactions en Environnements Immersifs}
	
	Fondateur dans le domaine, Bowman et al. \cite{bowman_introduction_2001} divisent les interactions utilisateurs en environnements virtuels en trois grande catégories:
	\begin{itemize}
		\item Navigation : comment l'utilisateur va se déplacer dans l'environnement
		\item Sélection et Manipulation : comment l'utilisateur va manipuler certains objets, et comment va-t-il dire à l'environnement lequel (ou lesquels) il souhaite manipuler
		\item Contrôle du système : comment l'utilisateur va altérer le déroulement même du système, de la simulation.
	\end{itemize}
	que nous allons rapidement aborder une par une.
	
	\subsubsection{Naviguer dans un Environnement Virtuel}
		La navigation permet à l'utilisateur de changer son point de vue sur l'environnement, elle doit aussi renforcer son immersion et faciliter sa spatialisation dans l'espace virtuel. Mal gérée, la navigation risque de provoquer la cinétose selon la sensibilité de l'utilisateur, semblable au mal des transports. La navigation est elle même divisée en trois modes : exploration, recherche et manœuvre, demandant différents degrés de contrôles. Dans ces travaux, Bowman et al. décrivent cinq métaphores classiquement utilisées pour les déplacements, que nous allons aborder rapidement :
		\begin{itemize}
		\item \textbf{Déplacement physique} : les mouvements du corps de l'utilisateur sont utilisés pour déplacer la caméra de l'environnement virtuel. Ceci est possible lorsque l'espace physique dans lequel est présent l'utilisateur est assez grand, et présente alors les meilleurs conditions pour l'utilisateur \cite{cherep_spatial_2020}. Les auteurs mentionnent aussi l'utilisation possible de tapis roulant ou de vélo immobilisé, permettant à l'utilisateur de se déplacer physiquement tout en faisant du sur-place, limitant l'espace physique nécessaire.
		\item \textbf{Déplacement "manuel"} : l'utilisateur vient saisir "l'air" l'environnant, et se tire dans sa direction, rappelant la métaphore d'une corde. Cette méthode fatigante est dite facile prendre en main.
		\item \textbf{Conduite} : l'utilisateur indique une direction, souvent la direction de son regard ou la direction pointée par une de ses manettes, dictant la direction du mouvement. Les auteurs présentent cette méthode comme étant efficace et générique. 
		\item \textbf{Sélection du point d'arrivée} : l'utilisateur indique le point auquel il souhaite se rendre et l'application se charge de l'y déplacer, en translation ou téléportation. Bowman et al. plébiscitaient à leur époque la translation plutôt que la téléportation, mais le déplacement de l'environnement sans déplacement du corps de l'utilisateur provoque la cinétose de celui-ci \cite{cherep_spatial_2020}.
		\item \textbf{Planification d'itinéraire} : un peu à la manière du déplacement précédent, l'utilisateur défini différents points de passages pour sa trajectoire. Ici encore, les risques de cinétoses sont élevés.
		\end{itemize}
		
	\subsubsection{Sélection et Manipulation dans un Environnement Virtuel}
	Ce type d'interaction permet à l'utilisateur de sélectionner un objet à manipuler, et d'en altérer la position et rotation dans l'environnement. Deux grands types d'interactions se retrouvent dans cette catégorie. Le premier consiste à capter la position de la main de l'utilisateur et de la représenter virtuelle dans l'environnement, lui permettant de saisir les objets que sa main virtuelle "touche". La méthode "Go-Go" permet d'élargir la portée de l'utilisateur au delà de la taille de son bras : la longueur du bras virtuel de celui-ci devient non-linéaire par rapport à celle de son bras réel \cite{poupyrev_go-go_1996}, lui permettant d'atteindre des objets éloignés. L'autre méthode consiste en un rayon laser tiré depuis l'utilisateur, souvent sa main (donnée par l'orientation et la position de sa manette), qui vient sélectionner l'objet ainsi visé. 
	
	Ces méthodes permettent aussi de représenter le "clic" traditionnel des interfaces classiques sur des boutons d'interface 2D, utilisables alors sur des interfaces 2D "flottantes" dans l'environnement virtuel.
	
	\subsubsection{Contrôle du Système dans un Environnement Virtuel}
	Ces contrôles permettent à l'utilisateur de modifier le fonctionnement de la simulation, ou de ses interactions, en sélectionnant le plus souvent des comportements prédéfinis. Ces interactions sont mises en places de manière similaires aux précédentes lorsque sont utilisés des menus tirés des interfaces 2D. Mais des commandes vocales, des commandes gestuelles ou l'utilisation d'outils réel dont la position a un sens permettent aussi de piloter ce genre d'interactions.
	
	
	\subsubsection{Interacteurs Tangibles}
	
		\begin{figure}
			\centering
			\includegraphics[width=.8\textwidth]{Pictures/Figures/TUIISHII.JPG}
			\caption{Tiré des travaux de Ishii et al. \cite{ishii_tangible_1997}. Équivalences entre des interacteurs "WIMP" et leurs homologues tangibles.}
			\label{TUIEx}
		\end{figure}	
	
			D'abord théorisés sous le noms d'"interfaces saisissables" \cite{fitzmaurice_bricks_1995}, le concept est ensuite étendu et devient "interfaces tangibles". Les interfaces tangibles (TUI pour \textit{Tangible User Interface}) sont une volonté de sortir des interfaces classiques dites "WIMP", "\textit{Windows, Icon, Menu, Pointer}", pour aller vers des interacteurs physiques ayant une représentation et une sémantique numérique, que l'on manipule naturellement \cite{ishii_tangible_1997}, la Figure \ref{TUIEx} en illustre quelques exemples. Dans ces travaux, Ihsii et al. \cite{ishii_tangible_1997} proposent notamment l'utilisation de tables interactives "metaDESK", capables de détecter et d'interpréter la sémantique d'objets posés sur sa surface. De la même manière, un tableau blanc pourrait reconnaitre des objets à sa surface. Ils proposent ensuite une "ambientROOM", littéralement "salle d'ambiance", où ils combinent l'utilisation d'une table interactive "cognitivement intensive" à des sensations périphériques pour convier des informations complémentaires. À ces fins, ils utilisent des sons, des déplacements d'air ou des lumières ambiantes.
			
			\begin{figure}
			\centering
			\includegraphics[width=.8\textwidth]{Pictures/Figures/KnobSlider.JPG}
			\caption{Tiré des travaux de Kim et al. \cite{kim_knobslider_2019}. Le "KnobSlider", un interacteur tangible capable de changer de forme afin de servir soit de bouton rotatif (C), soit de slider (A).}
			\label{KnobSlider}
		\end{figure}
			
			Leurs applications sont diverses, permettant par exemple une assistance pour la construction de requêtes complexes sur une base de donnée \cite{pereda_tui_2019}, ou une proposition de surfaces interactives permettant de jouer à un jeu de société "augmenté" \cite{villar_project_2018}. Plusieurs travaux s'intéressent à la forme de l'interacteur tangible, centrale dans la notion d'affordance, comme par exemple la proposition du "KnobSlider", un interacteur changeant de forme afin de proposer deux interactions, une interaction de bouton à tourner et une interaction de "slider" (bouton glissière), visibles sur la Figure \ref{KnobSlider} \cite{kim_knobslider_2019}. Dans la même recherche d'une forme modulable, des travaux proposent un interacteur à base de \textit{LEGO}, et donc complètement personalisable, afin de servir différents besoins, selon les applications ou les jeux \cite{arora_virtualbricks_2019}.
				
			Les TUI ont par la suite prouvé leurs capacités à faciliter l'immersion et l'apprentissage de ses utilisateurs \cite{zuckerman_tui_2013, fleck_marker-based_2015, cheng_affordances_2013}, et sont donc nombreux dans les applications pédagogiques. Par exemple, \textit{DEAPE Learn} propose une combinaison d'objets tangibles et de réalité augmentée afin d'illustrer et d'enseigner différents principes d'électromagnétisme, qui sont connus pour être abstrait et difficiles à comprendre pour les étudiants \cite{da_costa_realite_2019}. Une loupe augmentée est proposé dans des travaux visant à rapprocher les visiteurs de musées des différentes œuvres, en proposant des informations complémentaires aux objets que les utilisateurs regardent à travers \cite{damala_loupe_2016}. Un peu différemment, Veytizou et al. ont proposé d'utiliser une balance et des sphères de poids équivalents pour permettre à des enfants de répondre à une question de type "Likert", de 1 à 5 (ou 7). Les enfants sont connus pour donner des réponses très extrêmes à ces échelles, et l'utilisation de leur balance à réduit cette propension aux extrêmes tout en conservant des notes cohérentes \cite{veytizou_could_2018}.
	
	
	
				
	\section*{Conclusion}